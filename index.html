<!DOCTYPE html>
<style>

html, body {
	height: 100%;
}

body {
	margin: 0;
	position: relative;
}

#canvasEl {
	display: block;
	width: 100%;
	height: 100%;
}

#videoEl {
}

</style>
<!-- <audio id=mediaEl width=300 controls src="01 Endless Fantasy.mp3"></audio> -->
<!-- <video id=mediaEl width=300 controls src="The Rubens' Flame Tube - Seeing Sound Through Fire-pWekXMZJ2zM.mp4"></video> -->
<canvas id=canvasEl></canvas>
<script id="vShaderEl" type="x-shader">
attribute vec3 p;

uniform float aspect;
uniform float time;

varying vec3 pos;

void main() {
	gl_Position = vec4(p, 1.0);
	pos = p;
}

</script>
<script id="fShaderEl" type="x-shader">
precision highp float;

uniform float time;
uniform sampler2D soundtex;

varying vec3 pos;

void main(void) {
	float brightness = texture2D(soundtex, vec2(pos.x / 2.0 + 0.5, 0.0))[0];

	gl_FragColor = vec4(
		brightness,
		brightness,
		brightness,
		1.0
	);
}

</script>
<script>
'use strict';

const gl = canvasEl.getContext('webgl');


gl.enable(gl.DEPTH_TEST);
gl.enable(gl.CULL_FACE);

gl.enable(gl.BLEND);
gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA);

const cubeVertices = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, cubeVertices);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
	-1, 1, 0,
	-1, -1, 0,
	1, 1, 0,
	1, -1, 0,
]), gl.STATIC_DRAW);

const vShader = gl.createShader(gl.VERTEX_SHADER);
gl.shaderSource(vShader, vShaderEl.text);
gl.compileShader(vShader);

const fShader = gl.createShader(gl.FRAGMENT_SHADER);
gl.shaderSource(fShader, fShaderEl.text);
gl.compileShader(fShader);

const program = gl.createProgram();
gl.attachShader(program, vShader);
gl.attachShader(program, fShader);
gl.linkProgram(program);

gl.useProgram(program);

const timeLoc = gl.getUniformLocation(program, 'time');
const aspectLoc = gl.getUniformLocation(program, 'aspect');

const pLoc = gl.getAttribLocation(program, 'p');
gl.enableVertexAttribArray(pLoc);
gl.vertexAttribPointer(pLoc, 3, gl.FLOAT, false, 0, 0);

const soundTexLoc = gl.getAttribLocation(program, 'soundtex');
var soundTexture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, soundTexture);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

gl.pixelStorei(gl.UNPACK_ALIGNMENT, 1);

function resize() {
	const clientRect = canvasEl.getBoundingClientRect();
	canvasEl.width = clientRect.width * devicePixelRatio;
	canvasEl.height = clientRect.height * devicePixelRatio;
	gl.uniform1f(aspectLoc, gl.drawingBufferWidth / gl.drawingBufferHeight);
	gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
}

window.addEventListener('resize', resize);
resize();

class RubensTubens {
	constructor(analyser, texture) {
		let audioContext = new AudioContext;
		this.analyser = analyser;
		this.texture = texture;
	}

	start() {
		if (this.animationFrame)
			return;
		let draw = (now) => {
			this.draw(now);
			this.animationFrame = requestAnimationFrame(draw);
		};
		this.animationFrame = requestAnimationFrame(draw);
	}

	draw(now) {
		const inData = new Uint8Array(this.analyser.fftSize);
		this.analyser.getByteTimeDomainData(inData);

		const outData = new Uint8Array(674);
		let ofs = inData.length - outData.length * 2;
		let min = -1;
		for (let i = ofs - 5; i >= 5; i--) {
			let sum = 0;
			for (let j = -5; j <= 5; j++)
				sum += inData[i + j];
			if (min < 0 || sum < min) {
				ofs = i;
				min = sum;
			}
		}
		for (let i = 0; i < outData.length; i++) {
			outData[i] = (inData[i + ofs] / 2) + (inData[outData.length * 2 + ofs - i] / 2);
		}
		gl.bindTexture(gl.TEXTURE_2D, this.texture);
		gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, outData.length, 1, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, outData);
		gl.uniform1f(timeLoc, now / 1000);
		gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
	}
}

let tubens;
let ac;

// navigator.getUserMedia({audio: true}, stream => {
	tubens = new RubensTubens((() => {
		let audioContext = new AudioContext;
		ac = audioContext;
		let analyser = audioContext.createAnalyser();
		//analyser.fftSize = 4096;
		// let node = audioContext.createMediaStreamSource(stream);
		// let node = audioContext.createMediaElementSource(mediaEl);
		let node = audioContext.createOscillator();
		node.frequency.value = 261.63;
		// {
		// 	let rising = true;
		// 	setInterval(() => {
		// 		node.frequency.value *= rising ? 1.001 : 0.999;
		// 		if (node.frequency.value > 5000)
		// 			rising = false;
		// 		else if (node.frequency.value < 100)
		// 			rising = true;
		// 	}, 16);
		// }
		node.start();

		// let gainz = audioContext.createGain();
		// gainz.gain.value = 4;
		// node.connect(audioContext.destination);
		node.connect(analyser);
		// node.connect(gainz);
		// gainz.connect(analyser);
		return analyser;
	})(), soundTexture);
	tubens.start();
// }, err => { alert(`o shit: ${err}`); });

</script>
